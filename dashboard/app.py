import streamlit as st
import pandas as pd
import json
from datetime import datetime, time

# --- Page Configuration ---
st.set_page_config(
    page_title="Acme Logistics Call Metrics",
    page_icon="ðŸš›",
    layout="wide"
)

# --- Data Loading ---
@st.cache_data
def load_data():
    """Load call log data from the JSON file generated by the API."""
    try:
        # The dashboard is in a separate folder, so we need to go up one level to find the api folder
        with open("testData/call_logs.json", "r") as f:
            data = json.load(f)
        df = pd.DataFrame(data)
        # Convert timestamp string to datetime objects for filtering
        df['call_timestamp'] = pd.to_datetime(df['call_timestamp'])
        return df
    except (FileNotFoundError, json.JSONDecodeError):
        # Return an empty DataFrame if the file doesn't exist or is empty
        return pd.DataFrame()

df = load_data()

# --- Main Dashboard ---
st.title("ðŸš› Acme Logistics - Inbound Carrier Sales Dashboard")
st.markdown("This dashboard provides real-time metrics for the automated inbound call agent.")

if df.empty:
    st.warning("No call data found. The `call_logs.json` file is either missing or empty. Calls need to be logged by the API first.")
else:
    # --- Date Range Filtering ---
    st.sidebar.header("Filter by Date")
    min_date = df['call_timestamp'].min().date()
    max_date = df['call_timestamp'].max().date()

    start_date = st.sidebar.date_input("Start date", min_date, min_value=min_date, max_value=max_date)
    end_date = st.sidebar.date_input("End date", max_date, min_value=min_date, max_value=max_date)
    
    # Combine date and time for precise filtering
    df['call_timestamp'] = df['call_timestamp'].dt.tz_convert(None)

# Keep your naive start/end datetimes
    start_datetime = datetime.combine(start_date, time.min)
    end_datetime = datetime.combine(end_date, time.max)

    filtered_df = df[
        (df['call_timestamp'] >= start_datetime) & 
        (df['call_timestamp'] <= end_datetime)
    ]

    if filtered_df.empty:
        st.info("No data available for the selected date range.")
    else:
        # --- Key Performance Indicators (KPIs) ---
        total_calls = len(filtered_df)
        loads_accepted = filtered_df[filtered_df['outcome'] == 'Booked'].shape[0]
        acceptance_rate = (loads_accepted / total_calls * 100) if total_calls > 0 else 0

        col1, col2, col3 = st.columns(3)
        col1.metric("Total Calls Taken", f"{total_calls}")
        col2.metric("Loads Accepted (Booked)", f"{loads_accepted}")
        col3.metric("Acceptance Rate", f"{acceptance_rate:.2f}%")

        st.markdown("---")

        # --- Visualizations ---
        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader("Sentiment Analysis")
            sentiment_counts = filtered_df['sentiment'].value_counts()
            
            # Use a color map for sentiments
            sentiment_colors = {
                'Positive': '#2ca02c', # Green
                'Neutral': '#ff7f0e',  # Orange
                'Negative': '#d62728'  # Red
            }
            # Create a DataFrame for charting that respects the color mapping
            sentiment_df = pd.DataFrame({
                'Sentiment': sentiment_counts.index, 
                'Count': sentiment_counts.values
            })

            # Use st.bar_chart for simplicity and consistency
            st.bar_chart(sentiment_df.set_index('Sentiment'), color="#1f77b4")

        with col2:
            st.subheader("Call Outcomes")
            outcome_counts = filtered_df['outcome'].value_counts()
            st.bar_chart(outcome_counts)

        # --- Raw Data View ---
        st.subheader("Call Log Details")
        st.dataframe(
            filtered_df[['call_timestamp', 'mc_number', 'outcome', 'sentiment', 'final_rate', 'call_duration_seconds']]
            .sort_values(by="call_timestamp", ascending=False)
            .reset_index(drop=True)
        )
